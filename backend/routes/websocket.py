
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from loguru import logger
from watchfiles import watch, Change
import threading

router = APIRouter()
reload_clients = set()

@router.websocket("/ws/reload")
async def reload_socket(websocket: WebSocket):
    await websocket.accept()
    reload_clients.add(websocket)
    logger.info("ğŸ”Œ Neuer Reload-Client verbunden.")
    try:
        while True:
            data = await websocket.receive_text()
            if data.lower() == "ping":
                await websocket.send_text("pong")
    except WebSocketDisconnect:
        reload_clients.discard(websocket)
        logger.info("âŒ Reload-Client getrennt.")

def _should_ignore(changes) -> bool:
    for change, path in changes:
        p = str(path).replace("\\", "/")
        if p.endswith("/logs/server.log") or "/logs/" in p:
            return True
    return False


def start_watcher(path="backend/"):
    """
    Startet den Dateiwatcher in einem Daemon-Thread und gibt (thread, stop_event) zurÃ¼ck.
    Mit stop_event.set() lÃ¤sst er sich sauber beenden.
    """
    stop_event = threading.Event()

    def watcher():
        logger.info(f"ğŸ‘€ Watcher gestartet fÃ¼r: {path}")
        # watchfiles unterstÃ¼tzt stop_event â†’ Iterator endet, wenn Event gesetzt ist
        for changes in watch(path, stop_event=stop_event):
            # optional: zusÃ¤tzliche Entprellung / Noise-Filter hier einbauen
            if _should_ignore(changes):
                continue
            logger.info(f"ğŸ“¦ Ã„nderung erkannt: {changes}")

    thread = threading.Thread(target=watcher, daemon=True)
    thread.start()
    logger.info("ğŸ§µ Watcher-Thread gestartet.")
    return thread, stop_event
