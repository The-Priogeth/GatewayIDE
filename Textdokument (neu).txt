alles klar — hier ist der “Was-passiert-wann-wo”-Durchlauf, möglichst konkret, passend zu den drei Dateien (`bootstrap.py`, `konstruktor.py`, `main.py`) und der HMA-Konfiguration:

# 1) App-Start (FastAPI Lifespan)

1. `main.py` startet, ruft in `lifespan()` → `await bootstrap.ensure_runtime()`.
2. `bootstrap.ensure_runtime()`

   * Lädt `.env` (Model, API-Keys).
   * Baut **Zep**-Client und legt einen **Root-User** + **Root-Thread** (T1) an.
   * Erzeugt einen `ContextProvider` (liefert später `get()` als Kontextstring).
   * Definiert `memory_logger(role, name, content)`:

     * schreibt jeden Logeintrag asynchron in Zep-Thread **T1** (User↔System Spur),
     * aktualisiert danach die Zusammenfassung (Summary/Context) via `ctx_provider.refresh()`.
   * Baut **Demo-Profile** (innere Stimmen für SoM: Therapist, Programmer, Strategist, Critic).
   * Baut **Funktions-Agents** (äußerer Bereich): `TaskManager`, `Librarian`, `Trainer` (mit ihren Systemprompts).
   * Ruft `build_hma(...)`:

     * übergibt: LLM-Config, Demo-Profile, Funktions-Agents, `DEFAULT_HMA_CONFIG`, `memory_context_provider=ctx_provider.get`, `memory_logger=memory_logger`.
   * Legt alles in `app.state` ab (HMA-Paket, Zep, Thread-IDs, Provider).

Ergebnis: Backend ist “heiß”, HMA ist konstruiert, Zep speichert Logs.

# 2) HMA-Struktur (innen/außen) aus `konstruktor.py`

## 2.1 Innere Stimme (SOM)

* Es gibt einen **inneren GroupChat** aus den Demo-Profilen (`GroupChat` + `GroupChatManager`).
* Der **SocietyOfMindAgent (SOM)** bekommt:

  * `system_message` aus `DEFAULT_HMA_CONFIG.som_system_prompt` (Verhalten: in Ich-Form denken, Plan als JSON liefern, knapp, priorisieren, keine Hallu).
  * Er dient **nur** zum Denken/Planen/Finalisieren — **spricht nie direkt** mit User oder Funktions-Agents.

## 2.2 Äußerer Bereich (Funktions-Agents, “direkte Ansprache”)

* `TaskManager`, `Librarian`, `Trainer` liegen **außerhalb** des inneren SoM-Chats.
* Es gibt **keine Lobby-GroupChat** mehr.
* Der HMA ruft diese Agents **gezielt und sequenziell** über `_talk_direct(target, message)` auf:

  * sucht den Agent per Map `{task→TaskManager, lib→Librarian, trn→Trainer}`,
  * ruft bevorzugt `agent._run_inner(message)` (falls vorhanden) oder sonst `agent.generate_reply([...])`,
  * fängt Exceptions ab und gibt im Fehlerfall `""` zurück.

# 3) /chat-Aufruf (User → HMA)

1. `POST /chat` erhält `prompt`.
2. `main.py` schreibt den Prompt als Message in **Zep T1** (role=user, name=User).
3. Holt die aktuelle Zep-**Summary** und aktualisiert `ctx_provider.update(...)`.
4. Ruft `app.state.hma["hma"].step(prompt)` und gibt dessen Ergebnis zurück.

# 4) HMA.step(): die exakte Abfolge

Angenommen `user_text = "…"`.

1. **Kontext** holen: `ctx = memory_context_provider()` (Kurz-Summary aus Zep; leer, wenn nix da).

2. **Log**: `[User] → user: <user_text>`. (Zusätzlich in T1 via `memory_logger`.)

3. **Plan anfordern (innere Stimme)**: `_plan_with_som(user_text, ctx)`
   3.1 Bilde `plan_prompt` aus `DEFAULT_HMA_CONFIG.som_plan_template`. Darin stehen:

   * `{user_text}` (Originaleingabe),
   * `{context}` (Summary/Thread-Kontext),
   * `{capabilities}` (renderte Liste aus `capabilities`-Dict),
   * `{max_targets}` (Obergrenze für Anzahl geplanter Aktionen).
     3.2 **Log**: `[SOM:plan_prompt] → assistant: <…>` (abgeschnitten nach 300 Zeichen).
     3.3 Rufe `self.som.generate_inner_monologue_reply([...])` → SoM denkt & plant **intern**.
     3.4 **Erwartete Ausgabe** des SoM (aus Template-Instruktion): **reines JSON**:

   ```json
   {
     "thought": "Ich-Form, 1–2 Sätze",
     "actions": [
       {"target": "task|lib|trn", "message": "kurzer Auftrag"},
       ...
     ]
   }
   ```

   3.5 **Parsing**: `_safe_json_extract(plan_text)`
   - Erst direkter `json.loads(...)`. Wenn das scheitert, Regex `{...}`-Block extrahieren und nochmal parse.
   - Fehlersicher, tolerant gegenüber Vor-/Nachrede.
   3.6 `thought = data["thought"]` (str, optional), `actions = [{"target":..,"message":..}, …]` (gefiltert auf gültige Targets, max `{max_targets}`).
   3.7 **Fallback**: Wenn `actions` leer → `thought = "Ich kann diese Frage direkt beantworten."` (falls noch leer).

4. **Branch A: Keine Actions**

   * Baue `final_prompt` aus `DEFAULT_HMA_CONFIG.som_final_template` mit:

     * `{user_text}`,
     * `{aggregate} = thought oder "(keine externe Aktion nötig)"`.
   * Rufe `self.som.generate_inner_monologue_reply([...])` → SoM formuliert **finale Ich-Antwort**.
   * **Log** `[SOM] → assistant: <final>`.
   * **Return**: `{"final": True, "speaker": "SOM", "content": final}`.

5. **Branch B: Es gibt Actions** (sequenziell!)

   * **Log**: `[HMA:talk] → assistant: → <target> :: <message>` vor jedem Schritt.
   * Für **jede** Action (der Reihenfolge nach):

     * Rufe `_talk_direct(target, message)`:

       * Sucht Agent (Task/Librarian/Trainer),
       * ruft ggf. `agent._run_inner(msg)` oder `agent.generate_reply(...)`,
       * fängt Exceptions; gibt String (Antwort) oder `""`.
     * Hänge an Aggregat an (geordnet):

       ```
       #TASK: <message>
       <Agent-Antwort oder "(keine verwertbare Antwort)">
       ```

       (bzw. `#LIB:` / `#TRN:`)
   * Wenn alle durch sind → `aggregate = "\n\n".join(blocks)`.

6. **Finalisierung (immer SoM)**

   * Baue `final_prompt` aus `som_final_template`:

     * `{user_text}`,
     * `{aggregate}` (die geordnete Blocks-Sammlung).
   * Rufe `self.som.generate_inner_monologue_reply([...])`
   * **Log** `[SOM] → assistant: <final>`.
   * **Return**: `{"final": True, "speaker": "SOM", "content": final}`.

> WICHTIG: **Nur** SoM liefert die **endgültige** Antwort an den User. Funktions-Agents sprechen **nie** direkt zum User; sie liefern Arbeitsresultate an den HMA zurück, der sie dem SoM zur Finalisierung gibt.

# 5) Logs & Speicherung

* Jede `_log(role, sender, content)` schreibt:

  * in die Server-Logs (Loguru, Datei-Rotation),
  * **und** (wenn `memory_logger` gesetzt) als Message in Zep-Thread **T1** (mit Metadaten `role`, `name`).
* Damit hast du in Zep eine fortlaufende **Audit-Spur**: User-Eingaben, SOM-Prompts (gekappt), Plans, Actions, Final-Antworten.

# 6) Konfiguration (woher SoM weiß, “was es kann”)

* `DEFAULT_HMA_CONFIG` (in `hma_config.py`) liefert:

  * `som_system_prompt`: Verhalten der inneren Stimme (Ich-Form, plane zuerst, liefere JSON, keine Hallu, priorisieren…).
  * `som_plan_template`: Prompt-Schablone für **Plan** (mit `{capabilities}` Liste).
  * `som_final_template`: Prompt-Schablone für **Finalisierung**.
  * `capabilities`: deklaratives Register (task/lib/trn mit knappen Rollenbeschreibungen).
  * `max_parallel_targets`: Obergrenze **wie viele** Actions SoM maximal planen darf (auch wenn wir sie **sequenziell** abarbeiten).

SoM nutzt diese Templates 1:1 — d. h. **dort** definierst du das Verhalten, **ohne** Keyword-Routing. Alles ist **Kontext-getrieben** („Ich sollte …“, „ich frage …“).

# 7) Fehlerszenarien & Fallbacks

* **Plan ist kein JSON** → `_safe_json_extract` versucht Regex-Extraktion; wenn weiter leer: `actions=[]`, `thought` ggf. gesetzt → Branch A (direkt finalisieren).
* **Ungültiges Target** → wird beim Parsen gefiltert (nur `task|lib|trn` erlaubt).
* **Agent Fehler/Exception** → `_talk_direct` fängt ab → antwortet `""` → im Aggregat steht `(keine verwertbare Antwort)`. SoM sieht das und kann entsprechend vorsichtig formulieren.
* **Kein Kontext verfügbar** → `ctx=""`; Template füllt “(kein zusätzlicher Kontext)”.

# 8) Minimal-Beispiel (end-to-end)

**User**: „Baue mir einen 3-Schritte-Plan, wie ich das KI-Subsystem neu starte und Logs prüfe.“
**SOM (Plan-JSON)** (gedanklich):

```json
{
  "thought": "Ich kann das grob strukturieren und dem TaskManager eine kurze ToDo geben.",
  "actions": [
    {"target": "task", "message": "Erstelle 3 konkrete Schritte: Neustart Gateway-Container, Logs folgen, Healthcheck prüfen. Formuliere kompakt."}
  ]
}
```

**HMA**:

* ruft `_talk_direct("task", "...")` → TaskManager gibt 3 nummerierte Schritte zurück.
* baut Aggregat:

  ```
  #TASK: Erstelle 3 konkrete Schritte...
  1) docker compose restart gateway
  2) docker compose logs -f gateway | grep -E "ERROR|WARNING"
  3) curl http://localhost:8080/health
  ```
* **SOM finalisiert**: „Ich würde so vorgehen: 1) … 2) … 3) … Wenn du willst, starte ich direkt mit Schritt 1.“

# 9) Was du anpassen kannst (ohne Code-Logik zu ändern)

* In `DEFAULT_HMA_CONFIG`:

  * Tone/Strenge/Knappheit der SoM-Systemmessage,
  * Ausführlichkeit der `som_final_template`,
  * Rollen-Text der `capabilities` (beschreibt, **was** die Kanäle können),
  * `max_parallel_targets` (nur Plan-Obergrenze; Ausführung bleibt sequenziell).

---

Wenn du willst, kann ich dir jetzt noch eine **kurze „Trace-Ansicht“** in den Logs aktivieren (ein Flag), das die relevanten Abschnitte (Plan-JSON, jede Action, Agent-Antworten, Final-Prompt) gebündelt ausgibt — als eine komprimierte Block-Zusammenfassung nach jedem `/chat`.
